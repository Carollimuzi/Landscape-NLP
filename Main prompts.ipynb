{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501127d2",
   "metadata": {},
   "source": [
    "#  Prompts for automatic, few-shot annotation using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# OpenAI API\n",
    "openai.api_key = 'sk-'\n",
    "\n",
    "task_description = (\n",
    "    \"\"\"As an advanced linguist and NLP assistant, your task is to conduct Named Entity Recognition on park reviews. You have data on [Reviews] and [feature]. \n",
    "    The [Features] provides definitions for four major classes (with prefixes N_, Act_, F_, and P_) that cover subcategories of park features. \"N_\" stands for natural features, \"F_\" for facilities, \"Act_\" for activities, and \"P_\" for perceptions. \n",
    "    Your goal is to extract all relevant entities from [Reviews] that match definitions in feature_definitions.\n",
    "    Output directly in the format of few_shot_examples.\n",
    "    Each numbered sentence outputs a result with the original number.\"\"\")\n",
    "\n",
    "# few-shot learning example\n",
    "few_shot_examples = (\n",
    "    \"Few shot examples:\\n\"\n",
    "    \"\"\" [27559\tgreat for running because of the slope and altitude.\n",
    "         20664\tlovely park for a jog or walk, toilet is under repair.]\n",
    "    output: \n",
    "     {\"27559\": {\"Act_active\": \"running\",\"N_Terrain\": \"slope, altitude\"}}\n",
    "     {\"20664\": {\"Act_active\": \"jog, walk\", \"F_service\": \"toilet\"}}\n",
    "     \"\"\")\n",
    "\n",
    "reviews = []\n",
    "with open(\"GM_split_sentence_150_300.csv\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            if not row[26] or not row[2]:\n",
    "                continue\n",
    "            reviews.append(row[26] + \"\\t\" + row[2])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "feature_definitions = {\n",
    "    \"Act_stationary\": \"Stationary activities such as resting, standing, sitting, lying down, waiting.\",\n",
    "    \"Act_active\": \"Moderate or higher intensity physical activities, including all walk, jog.\",\n",
    "    \"Act_light\": \"Light physical activities or activities with uncertain intensity suitable for all ages, like family activities, BBQ.\",\n",
    "\n",
    "    \"F_stationary\": \"Facilities for stationary activities, such as benches, gazebos, pavilion.\",\n",
    "    \"F_active\": \"Facilities for moderate or higher intensity physical activities and exercise.\",\n",
    "    \"F_recreation\": \"Facilities for light recreational activities, like playground, picnic area\",\n",
    "    \"F_cultural\": \"Facilities for light cultural/historical activities, like museums, memorial halls, exhibition, cultural sites\",\n",
    "    \"F_catering\": \"Catering facility/building for eating and drinking, including shops, vending machines, water fountains\",\n",
    "    \"F_Transport\": \"Transport facility, parking lots, bus, subway station\",\n",
    "    \"F_Sign\": \"Facilities and systems providing park information and navigation, including directional signs, maps, and educational panels.\",\n",
    "    \"F_path\": \"All kinds of Trails, path and road.\",\n",
    "    \"F_service\": \"Facilities for supporting service such as visitor center, toilets\",\n",
    "    \"F_lights\": \"lighting equipment\",\n",
    "\n",
    "    \"N_Terrain\": \"Terrain features, such as hill, slopes, stairs, and natural landforms.\",\n",
    "    \"N_Plant\": \"Plant/vegetation. Excluding flower.\",\n",
    "    \"N_Flower\": \"Flower, excluding terms used to describe other objects, like flower shape.\",\n",
    "    \"N_Animal\": \"Animal, excluding terms used to describe other things, like goat ice cream.\",\n",
    "    \"N_Water\": \"Water bodies, such as lakes, rivers, and ponds, excluding drinking water facilities\",\n",
    "    \"N_Weather\": \"Describing or indicating weather.\",\n",
    "    \"N_Color\":  \"Color, excluding terms used to describe other objects, like golden hours.\",\n",
    "\n",
    "    \"P_Sound\": \"Auditory sensory,including natural and artificial sounds.\",\n",
    "    \"P_Olf\": \"Olfaction/smell sensory, like spice.\",\n",
    "    \"P_Tactile\": \"Sensory derived from touching natural and man-made surfaces, like the perception of texture, temperature, moisture, and firmness of surfaces and materials, like breeze blows\",\n",
    "    \"P_Crowd\": \"Terms relating crowd.\"\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": task_description},\n",
    "    {\"role\": \"system\", \"content\": few_shot_examples},\n",
    "]\n",
    "\n",
    "f = open(\"final_file_150300.json\", \"a\")  \n",
    "\n",
    "for index in range(0, len(reviews), 50):\n",
    "    temp_reviews = reviews[index: index + 50]\n",
    "    # review = ['\"\"\"' + \"\\n\".join(temp_reviews) + '\"\"\"']\n",
    "    review = \"\\n\".join(temp_reviews)\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"[Review {index // 50 + 1}]: {review}\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"[Feature Definitions]: {feature_definitions}\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages\n",
    "    )\n",
    "    f.write(response['choices'][0]['message']['content'])\n",
    "    f.write(\"\\n\")  \n",
    "    \n",
    "    print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a6e99",
   "metadata": {},
   "source": [
    "# Prompts (lables) for zero-shots classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b47e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# Specify the device (cuda:0 refers to GPU; use cuda:1, cuda:2, etc., for multiple GPUs)\n",
    "device = 0\n",
    "# Load the classifier with GPU support\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ddde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "aesthetic_df = pd.read_csv('test_lexicon_LLM.csv')\n",
    "\n",
    "texts_to_classify = aesthetic_df['text'].tolist()\n",
    "\n",
    "# weather,path, lighting 10\n",
    "# candidate_labels = [ \n",
    "        # \"mentions weather\",  \"does not mention weather\", \"involves physical paths/pathways\",\n",
    "        # \"involves physical tracks for activities\", \"involves physical trails/roads/walkways\",\n",
    "        # \"involves physical stairs/ bridges\", \"does not involve any physical tracks, trails, paths, roads, pathways, walkways, or stairs\",\n",
    "        # \"involves lighting facilities/equipment\", \"involves lighting levels\", \"not related to lighting facilities or equipment\"\n",
    "# ]\n",
    "# terrain, animal, water 10\n",
    "# candidate_labels = [\n",
    "#         \"relate to terrain\", \"relate to elevation\", \n",
    "#         \"relate to changes in elevation\", \"does not talk about any terrain types, flat, elevation or changes in elevation\",\n",
    "#         \"references to actual fauna/animals present\", \"reference to insects\", \"No references to fauna/animals or insects\",  \n",
    "#         \"involves water landscapes\", \"involves drinking water facilities\",\"not related to water landscapes\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# sign, sound, olf 11\n",
    "# candidate_labels = [\n",
    "#         \"involves signage/marking facilities/systems\", \"mentions getting lost or losing directions\" ,\n",
    "#         \"mentions inability to find directions\", \"not related to signage/marking facilities or systems\", \n",
    "#         \"mentions sound\", \"mentions noise\", \"mentions quietness/tranquility\", \"not related to sound/ noise/quietness/tranquility\",\n",
    "#         \"mentions olfaction/smell perception\", \"mentions fresh air\", \"not related to olfaction/smell perception or fresh air\"\n",
    "# ]\n",
    "\n",
    "# F_active,F_recreation, F_cultural, F_Transport 9\n",
    "# candidate_labels = [\n",
    "#         \"comment facilities for moderate to vigorous physical activity \", \n",
    "#         \"mentions facilities/structure/courses mainly for exercise\",\n",
    "#         \"nothing to do with facilities for moderate to vigorous physical activity\",\n",
    "        \n",
    "#         \"mentions facilities for recreation instaed of for active physical activity\", \n",
    "#         \"does not mention facilities for recreation\",\n",
    "#         \"mention facilities for active physical activity instaed of recreation\",\n",
    "        \n",
    "#         \"mentions facilities/installations/sites commemo-rating history, or for cultural and artistic viewing\", \n",
    "#         \"does not mention facilities/installations/sites serving as historical or cultural and artistic points in parks\", \n",
    "        \n",
    "#         \"mentions facilities for transport\", \"does not mention facilities for transport\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Act_stationary, Act_light, F_stationary, F_service 10\n",
    "# candidate_labels = [\n",
    "#         \"mentions sedentary activity, like rest, chill, relax, etc\",\n",
    "#         \"relate to static activity\",\n",
    "            \n",
    "#          \"mentions light physical activity instead of moderate-to-vigorous physical activity or exercise\",\n",
    "#         \"mentions outdoor activities of light intensity, such as camping, picnicking, fishing, and BBQ\",\n",
    "#         \"does not mention any outdoor activities of light intensity, such as camping, picnicking, fishing, and BBQ\",\n",
    "        \n",
    "#         \"mentions facilities/structures providing chances for rest or relative static activity\", \n",
    "#         \"does not mention facilities/structures/building providing chances for rest or relative static activity\" ,   \n",
    "        \n",
    "#         \"involve the evaluation of general service facilities offering sale, repair, rental, emergency, toielt, etc.\", \n",
    "#         \"not involve the evaluation of general service facilities\", \n",
    "#         \"mentions facilities providing convenience service/information/tickets for visitors\"\n",
    "# ]\n",
    "\n",
    "# # Act_active, P_Crowd, N_Color, F_catering 8\n",
    "# candidate_labels = [\n",
    "#         \"relate to moderate to vigorous physical activity\",\n",
    "#         \"nothing to do with moderate to vigorous physical activity\",\n",
    "#         \"mentions facilities/structures/equipments providing drinks/drinking water or food\", \n",
    "#         \"does not mention facilities/structures/equipments providing drinks or food\",\n",
    "#         \"mentions color\", \"does not mention any color\",\n",
    "#         \"mentions crowd or not crowd\", \"nothing about whether crowd or not crowd\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# N_Plant, N_Flower, P_Tactile 10\n",
    "# candidate_labels = [\n",
    "#         \"mentions perceptions, like insect bite, hot or cold.\" ,                  \n",
    "#         \"mentions tactile perceptions, such as feeling breezes, wetness, temperature, etc\",\n",
    "#         \"mentions perceptions, like insect bite, breeze, humid, dry, hot or cold.\"  ,\n",
    "#         \"does not mention any perceptions, like insect bite, breeze, humid, dry, hot or cold.\",\n",
    "        \n",
    "#         \"mentions real vegetations/plants/greenery/flora\", \n",
    "#         \"mentions flora which refer to artificial installations in the shape of flora\",\n",
    "#         \"does not mention vegetations/plants/greenery/flora\",\n",
    "            \n",
    "#         \"mention flowers\", \"comment real plantations with flowers\", \"does not mention any flowers\"\n",
    "# ]\n",
    "\n",
    "batch_size = 10  # Set batch size\n",
    "save_interval = 5  # Save every 5 batches\n",
    "\n",
    "# Initialize a counter for the number of batches processed\n",
    "batches_processed = 0\n",
    "\n",
    "# Process in batches\n",
    "for start_index in range(0, len(texts_to_classify), batch_size):\n",
    "    end_index = start_index + batch_size\n",
    "    batch_texts = texts_to_classify[start_index:end_index]\n",
    "    \n",
    "    # Classify the batch\n",
    "    outputs = classifier(batch_texts, candidate_labels, multi_label=True)\n",
    "    \n",
    "    for batch_index, output in enumerate(outputs):\n",
    "        index = start_index + batch_index  # Original DataFrame index\n",
    "        \n",
    "        # Create a dictionary to hold the label and its corresponding score\n",
    "        labels_scores = {label: score for label, score in zip(output['labels'], output['scores'])}\n",
    "        \n",
    "        # Add probabilities to DataFrame\n",
    "        for label in candidate_labels:\n",
    "            column_name = f\"prob_{label.replace(' ', '_')}\"  # Sanitize label to create a valid column name\n",
    "            aesthetic_df.at[index, column_name] = labels_scores.get(label, 0.0)  # Use 0.0 if label is not found\n",
    "\n",
    "    batches_processed += 1\n",
    "    \n",
    "    # Save after every 5 batches processed\n",
    "    if batches_processed % save_interval == 0:\n",
    "        aesthetic_df.to_csv('test_lexicon_LLM.csv', index=False)\n",
    "        print(f\"Processed and saved after batch {batches_processed}\")\n",
    "\n",
    "# Save the final batch if it wasn't saved in the loop\n",
    "if batches_processed % save_interval != 0:\n",
    "    aesthetic_df.to_csv('test_lexicon_LLM.csv', index=False)\n",
    "    print(f\"Processed and saved the final batch. Total batches processed: {batches_processed}\")\n",
    "\n",
    "# Print DataFrame including classification results with probabilities\n",
    "print(aesthetic_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3d226",
   "metadata": {},
   "source": [
    "# Prompts for identifying sentences containing underrepresented entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "aesthetic_df = pd.read_csv('GMTA_Aspect_sentence_prob.csv')\n",
    "\n",
    "texts_to_classify = aesthetic_df['split_sentence'].tolist()\n",
    "\n",
    "candidate_labels = [ \n",
    "    \"Mention facilities for moderate to high intensity physical activity\", \"Mention carpark/accessibility/transporting commnets\",\n",
    "    \"mention sedentary or static activities\", \"mention transportation related facilities in the park\", \n",
    "    \"mention terrain\", \"mention lighting\", \"mention touch hearing smell perception\", \"mention facilities in park\"\n",
    "    \n",
    "]\n",
    "\n",
    "batch_size = 10  # Set batch size\n",
    "save_interval = 5  # Save every 5 batches\n",
    "\n",
    "# Initialize a counter for the number of batches processed\n",
    "batches_processed = 0\n",
    "\n",
    "# Process in batches\n",
    "for start_index in range(0, len(texts_to_classify), batch_size):\n",
    "    end_index = start_index + batch_size\n",
    "    batch_texts = texts_to_classify[start_index:end_index]\n",
    "    \n",
    "    # Classify the batch\n",
    "    outputs = classifier(batch_texts, candidate_labels, multi_label=True)\n",
    "    \n",
    "    for batch_index, output in enumerate(outputs):\n",
    "        index = start_index + batch_index  # Original DataFrame index\n",
    "        \n",
    "        # Create a dictionary to hold the label and its corresponding score\n",
    "        labels_scores = {label: score for label, score in zip(output['labels'], output['scores'])}\n",
    "        \n",
    "        # Add probabilities to DataFrame\n",
    "        for label in candidate_labels:\n",
    "            column_name = f\"prob_{label.replace(' ', '_')}\"  # Sanitize label to create a valid column name\n",
    "            aesthetic_df.at[index, column_name] = labels_scores.get(label, 0.0)  # Use 0.0 if label is not found\n",
    "\n",
    "    batches_processed += 1\n",
    "    \n",
    "    # Save after every 5 batches processed\n",
    "    if batches_processed % save_interval == 0:\n",
    "        aesthetic_df.to_csv('Aspect_sentence_prob.csv', index=False)\n",
    "        print(f\"Processed and saved after batch {batches_processed}\")\n",
    "\n",
    "# Save the final batch if it wasn't saved in the loop\n",
    "if batches_processed % save_interval != 0:\n",
    "    aesthetic_df.to_csv('GMTA_Aspect_sentence_prob.csv', index=False)\n",
    "    print(f\"Processed and saved the final batch. Total batches processed: {batches_processed}\")\n",
    "\n",
    "# Print DataFrame including classification results with probabilities\n",
    "print(aesthetic_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
