experiment:
  exp_dir: experiments/
  exp_name: ufet_mcce
  seed: 42

task: mcce-entity-typing

dataset:
  data_file:
    train: 'https://www.modelscope.cn/api/v1/datasets/izhx404/ufet/repo/files?Revision=master&FilePath=train.json'
    valid: 'https://www.modelscope.cn/api/v1/datasets/izhx404/ufet/repo/files?Revision=master&FilePath=dev.json'
    test: 'https://www.modelscope.cn/api/v1/datasets/izhx404/ufet/repo/files?Revision=master&FilePath=test.json'
    cand: PATH_TO_CAND
  tokenizer: blank
  labels: 'https://www.modelscope.cn/api/v1/datasets/izhx404/ufet/repo/files?Revision=master&FilePath=labels.txt'

preprocessor:
  type: multilabel-concat-typing-mcce-preprocessor
  max_length: 300
  cand_size: 256

data_collator: MultiLabelConcatTypingDataCollatorWithPadding

model:
  type: multilabel-concat-typing-model-mcce-s
  embedder:
    model_name_or_path: roberta-base
    drop_special_tokens: false
  dropout: 0
  decoder:
    type: linear
  loss_function: WBCE
  pos_weight: 1

train:
  trainer: typing-trainer
  max_epochs: 20
  dataloader:
    batch_size_per_gpu: 4
  optimizer:
    type: AdamW
    lr: 1.0e-5
  lr_scheduler:
    type: cosine
    warmup_rate: 0
    options:
      by_epoch: false
  hooks:
    - type: "CheckpointHook"
      interval: 100
    - type: "BestCkptSaverHook"
      save_file_name: "best_model.pth"
    - type: "EvaluationHook"
      interval: 100
      by_epoch: False

evaluation:
  dataloader:
    batch_size_per_gpu: 32
  metrics: typing-threshold-metric
