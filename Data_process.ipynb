{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d11ccf",
   "metadata": {},
   "source": [
    "# convert csv to json for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04373994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: JSON-Lines file saved -> GM_reviews_all.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 1 Read CSV file\n",
    "csv_file_path = \"GM_reviews_all.csv\"  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_file_path, encoding='latin1')\n",
    "\n",
    "# 2 Ensure 'id' column exists; if not, generate it\n",
    "if 'id' not in df.columns:\n",
    "    df['id'] = range(1, len(df) + 1)\n",
    "\n",
    "# 3 Preprocess: Tokenize sentences while preserving punctuation\n",
    "def preprocess_text(sentence):\n",
    "    \"\"\"\n",
    "    Tokenize the sentence into words while preserving punctuation.\n",
    "    \"\"\"\n",
    "    words = re.findall(r\"[A-Za-z]+|[^A-Za-z\\s]+\", sentence)\n",
    "    return words\n",
    "\n",
    "# Process data\n",
    "json_data = []\n",
    "for _, row in df.iterrows():\n",
    "    split_text = row[\"split_sentence\"]\n",
    "    words = preprocess_text(split_text)\n",
    "\n",
    "    sample = {\n",
    "        \"text\": words,\n",
    "        \"spans\": [],  # Empty spans for now\n",
    "        \"id\": str(row[\"id\"])  # Convert id to string format\n",
    "    }\n",
    "    json_data.append(sample)\n",
    "\n",
    "# 4 Save as JSON-Lines format\n",
    "output_jsonl_path = \"GM_reviews_all.json\"\n",
    "\n",
    "with open(output_jsonl_path, 'w') as outfile:\n",
    "    for record in json_data:\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "print(f\"4: JSON-Lines file saved -> {output_jsonl_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e4653",
   "metadata": {},
   "source": [
    "# convert predict file to csv file for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8cf47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID added to GM_reviews_all_pred0321.json\n",
      "CSV saved to GM_reviews_all_pred0321.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def add_ids_for_predicted(inputid_file, inputpre_file, output_file):\n",
    "    with open(inputid_file, 'r', encoding='utf-8') as file1:\n",
    "        ids = [json.loads(line)['id'] for line in file1]\n",
    "    \n",
    "    with open(inputpre_file, 'r', encoding='utf-8') as file2, open(output_file, 'w', encoding='utf-8') as file2_updated:\n",
    "        for i, line in enumerate(file2):\n",
    "            data = json.loads(line)\n",
    "            if i < len(ids): \n",
    "                data['id'] = ids[i]  \n",
    "            file2_updated.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"ID added to {output_file}\")\n",
    "\n",
    "\n",
    "def convert_pred_to_csv(json_file, output_csv_path):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        max_tokens_length = max(len(item[\"tokens\"]) for item in data)\n",
    "        header = [\"\" for _ in range(max_tokens_length)]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for item in data:\n",
    "            tokens_row = [\"\" for _ in range(max_tokens_length)]\n",
    "            for i, token in enumerate(item[\"tokens\"]):\n",
    "                tokens_row[i] = token\n",
    "            writer.writerow(tokens_row)\n",
    "\n",
    "            for span in item[\"predicts\"]:\n",
    "                row = [\"\" for _ in range(max_tokens_length)]\n",
    "                start, end, entity_type = span[0], span[1], span[2]\n",
    "                for i in range(start, end):\n",
    "                    row[i] = entity_type\n",
    "                writer.writerow(row)\n",
    "\n",
    "            id_row = [\"#ID\"] + [item[\"id\"]] + [\"\" for _ in range(max_tokens_length - 2)]\n",
    "            writer.writerow(id_row)\n",
    "            writer.writerow([])\n",
    "\n",
    "    print(f\"CSV saved to {output_csv_path}\")\n",
    "\n",
    "inputid_json = \"GM_reviews_all.json\"  
    "inputpre_json = \"pred_modern.json\"  
    "output_json = \"GM_reviews_all_pred0321.json\"  
    "output_csv_path = \"GM_reviews_all_pred0321.csv\"  
    "\n",
    "add_ids_for_predicted(inputid_json, inputpre_json, output_json)\n",
    "convert_pred_to_csv(output_json, output_csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a06633",
   "metadata": {},
   "source": [
    "# checking annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "507df2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21406,\n",
       " [(1,\n",
       "   'there are also mountain bikers who take a specially constructed path that is filled with sharp turns on undulating terrain .                                                        '),\n",
       "  (5,\n",
       "   '#ID 25140                                                                           '),\n",
       "  (7,\n",
       "   'a place where you sees many athletes jogging , running and doing exercise here .                                                              '),\n",
       "  (11,\n",
       "   '#ID 27484                                                                           '),\n",
       "  (13,\n",
       "   'well - maintained with sufficient signage and facilities for collection and use of hot spring water 10 / 10 recommend                                                         ')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = \"20250110check_modified.csv\"\n",
    "filtered_rows_corrected = []\n",
    "\n",
    "with open(file_path, 'r', newline='', encoding='gbk') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    for line_number, row in enumerate(reader, start=1):\n",
    "        non_empty_cells = [cell for cell in row if cell.strip()]\n",
    "        if len(non_empty_cells) > 1:\n",
    "            row_str = \" \".join(row) \n",
    "            \n",
    "            split_by_spaces = row_str.split()\n",
    "            for i in range(len(split_by_spaces) - 1):\n",
    "                gap = row_str[row_str.find(split_by_spaces[i]) + len(split_by_spaces[i]): row_str.find(split_by_spaces[i + 1])]\n",
    "                if \" \" in gap:  \n",
    "                    filtered_rows_corrected.append((line_number, row_str))\n",
    "                    break  \n",
    "\n",
    "\n",
    "num_filtered_corrected_rows = len(filtered_rows_corrected)\n",
    "sample_filtered_corrected_rows = filtered_rows_corrected[:5]  \n",
    "\n",
    "num_filtered_corrected_rows, sample_filtered_corrected_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a98e7b",
   "metadata": {},
   "source": [
    "# Convert annotation data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402b87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def csv_to_custom_json(input_csv_path, output_json_path):\n",
    "    \"\"\"\n",
    "    Converts a CSV file into target JSON format, where each row represents a sample \n",
    "    containing text, annotated entity spans, and a sample ID.\n",
    "\n",
    "    Example:\n",
    "    Input CSV:\n",
    "        hello, world, this, is, a, test\n",
    "        , , , , , B-ENTITY\n",
    "        #ID, sample_1\n",
    "\n",
    "    Output JSON:\n",
    "        {\"text\": [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"], \"spans\": [{\"start\": 5, \"end\": 6, \"type\": \"B-ENTITY\"}], \"id\": \"sample_1\"}\n",
    "    \"\"\"\n",
    "    with open(input_csv_path, 'r', newline='', encoding='latin1') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        samples = []\n",
    "        sample = {}\n",
    "        spans = []\n",
    "        text_line_read = False\n",
    "        \n",
    "        for row in reader:\n",
    "            if not any(row):\n",
    "                continue\n",
    "            \n",
    "            if not text_line_read:\n",
    "                text = []\n",
    "                for i, word in enumerate(row):\n",
    "                    if word or (i < len(row) - 1 and row[i + 1]):\n",
    "                        text.append(word)\n",
    "                sample['text'] = text\n",
    "                text_line_read = True\n",
    "                continue\n",
    "            \n",
    "            if row[0] != '#ID':\n",
    "                start = None\n",
    "                end = None\n",
    "                span_type = None\n",
    "                for idx, cell in enumerate(row):\n",
    "                    if cell != '':\n",
    "                        if start is None:\n",
    "                            start = idx\n",
    "                        end = idx + 1\n",
    "                        span_type = cell\n",
    "                if start is not None and span_type is not None:\n",
    "                    spans.append({\"start\": start, \"end\": end, \"type\": span_type})\n",
    "            \n",
    "            elif row[0] == '#ID':\n",
    "                sample['id'] = row[1]\n",
    "                sample['spans'] = spans\n",
    "                samples.append(sample)\n",
    "                sample = {}\n",
    "                spans = []\n",
    "                text_line_read = False\n",
    "        \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        for sample in samples:\n",
    "            if sample['spans']:\n",
    "                json_file.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "                \n",
    "input_csv_path = '20250110check_modified.csv'\n",
    "output_json_path = '20250110check_modified.json' \n",
    "csv_to_custom_json(input_csv_path, output_json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
